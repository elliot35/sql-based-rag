services:
  db:
    image: postgres:13
    restart: always
    env_file: .env
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
      interval: 5s
      timeout: 5s
      retries: 5

  # Backend service without GPU support (for OpenAI)
  backend:
    profiles: ["openai"]
    build:
      context: .
      dockerfile: backend/Dockerfile
    ports:
      - "8000:8000"
    depends_on:
      db:
        condition: service_healthy
    env_file: .env
    environment:
      DATABASE_URL: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@db:5432/${POSTGRES_DB}?sslmode=disable
    command: bash -c "./download_model.sh && ./entrypoint.sh uvicorn backend.main:app --host 0.0.0.0 --port 8000"

  # Backend service with GPU support (for local LLama)
  backend-gpu:
    profiles: ["local"]
    build:
      context: .
      dockerfile: backend/Dockerfile
    ports:
      - "8000:8000"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    depends_on:
      db:
        condition: service_healthy
    env_file: .env
    environment:
      DATABASE_URL: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@db:5432/${POSTGRES_DB}?sslmode=disable
    volumes:
      - ./models:/app/models
    command: bash -c "./download_model.sh && ./entrypoint.sh uvicorn backend.main:app --host 0.0.0.0 --port 8000"

  frontend:
    build:
      context: .
      dockerfile: frontend/Dockerfile
    ports:
      - "8501:8501"
    depends_on:
      - ${BACKEND_SERVICE:-backend}
    environment:
      - BACKEND_URL=http://${BACKEND_SERVICE:-backend}:8000

volumes:
  postgres_data: 